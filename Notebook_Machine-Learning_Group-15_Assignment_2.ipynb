{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import OneClassSVM, SVR\n",
    "from sklearn.linear_model import Ridge, SGDRegressor, Lasso\n",
    "\n",
    "# set random seed \n",
    "RSEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48199</th>\n",
       "      <td>None</td>\n",
       "      <td>283.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2018-09-30 19:00:00</td>\n",
       "      <td>3543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48200</th>\n",
       "      <td>None</td>\n",
       "      <td>282.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 20:00:00</td>\n",
       "      <td>2781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48201</th>\n",
       "      <td>None</td>\n",
       "      <td>282.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Thunderstorm</td>\n",
       "      <td>proximity thunderstorm</td>\n",
       "      <td>2018-09-30 21:00:00</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48202</th>\n",
       "      <td>None</td>\n",
       "      <td>282.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 22:00:00</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48203</th>\n",
       "      <td>None</td>\n",
       "      <td>282.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 23:00:00</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48204 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      holiday    temp  rain_1h  snow_1h  clouds_all  weather_main  \\\n",
       "0        None  288.28      0.0      0.0          40        Clouds   \n",
       "1        None  289.36      0.0      0.0          75        Clouds   \n",
       "2        None  289.58      0.0      0.0          90        Clouds   \n",
       "3        None  290.13      0.0      0.0          90        Clouds   \n",
       "4        None  291.14      0.0      0.0          75        Clouds   \n",
       "...       ...     ...      ...      ...         ...           ...   \n",
       "48199    None  283.45      0.0      0.0          75        Clouds   \n",
       "48200    None  282.76      0.0      0.0          90        Clouds   \n",
       "48201    None  282.73      0.0      0.0          90  Thunderstorm   \n",
       "48202    None  282.09      0.0      0.0          90        Clouds   \n",
       "48203    None  282.12      0.0      0.0          90        Clouds   \n",
       "\n",
       "          weather_description            date_time  traffic_volume  \n",
       "0            scattered clouds  2012-10-02 09:00:00            5545  \n",
       "1               broken clouds  2012-10-02 10:00:00            4516  \n",
       "2             overcast clouds  2012-10-02 11:00:00            4767  \n",
       "3             overcast clouds  2012-10-02 12:00:00            5026  \n",
       "4               broken clouds  2012-10-02 13:00:00            4918  \n",
       "...                       ...                  ...             ...  \n",
       "48199           broken clouds  2018-09-30 19:00:00            3543  \n",
       "48200         overcast clouds  2018-09-30 20:00:00            2781  \n",
       "48201  proximity thunderstorm  2018-09-30 21:00:00            2159  \n",
       "48202         overcast clouds  2018-09-30 22:00:00            1450  \n",
       "48203         overcast clouds  2018-09-30 23:00:00             954  \n",
       "\n",
       "[48204 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test read in data\n",
    "data_metro = pd.read_csv(\"data/dataset_MetroInterstateTrafficVolume.csv\", sep=\",\")\n",
    "data_news = pd.read_csv(\"data/dataset_OnlineNewsPopularity.csv\", sep=\",\")\n",
    "data_realestate = pd.read_excel(\"data/dataset_RealEstateValuation.xlsx\")\n",
    "data_metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(model, X_train, X_test, y_train):\n",
    "    model.fit(X_train,y_train.values.ravel())\n",
    "    return model.predict(X_test)\n",
    "\n",
    "def evaluate_prediction(y_test, y_pred, data_name, model_name):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(model_name, ', ', data_name)\n",
    "    print(\"MSE: \",mse,\"\\nR2 Score: \",r2)\n",
    "    print(\"-\"*50)\n",
    "    # g=plt.scatter(y_test, y_pred)\n",
    "    # g.axes.set_xlabel('True Values ')\n",
    "    # g.axes.set_ylabel('Predictions ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    # reset index\n",
    "    X_train = X_train.reset_index().drop(['index'], axis=1)\n",
    "    X_test = X_test.reset_index().drop(['index'], axis=1)\n",
    "    \n",
    "    scaled_features_train = X_train.copy()\n",
    "    scaled_features_test = X_test.copy()\n",
    "\n",
    "    # only select numeric columns\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    columns_to_scale = X_train.select_dtypes(include=numerics).columns\n",
    "    \n",
    "    features_to_scale_train = scaled_features_train[columns_to_scale]\n",
    "    features_to_scale_test = scaled_features_test[columns_to_scale]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(features_to_scale_train)\n",
    "    scaled_features = pd.DataFrame(scaler.transform(features_to_scale_train))\n",
    "    scaled_features_train[columns_to_scale] = scaled_features\n",
    "    scaled_features = pd.DataFrame(scaler.transform(features_to_scale_test))\n",
    "    scaled_features_test[columns_to_scale] = scaled_features\n",
    "    \n",
    "    return scaled_features_train, scaled_features_test\n",
    "\n",
    "def process_missing_values(X_train, y_train):\n",
    "    # drop missing values\n",
    "    X_train = X_train.dropna()\n",
    "    y_train = y_train.dropna()\n",
    "    \n",
    "    return X_train, y_train\n",
    "\n",
    "def process_outliers(X_train, y_train):\n",
    "    # only select numeric columns\n",
    "    numerics = ['uint8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    X_train = X_train.select_dtypes(include=numerics)\n",
    "\n",
    "    # identify outliers in the training dataset\n",
    "    outlier_predictor = OneClassSVM(nu=0.02)\n",
    "    y_hat = outlier_predictor.fit_predict(X_train)\n",
    "    unique, counts = np.unique(y_hat, return_counts=True)\n",
    "\n",
    "    # select all rows that are not outliers\n",
    "    outlier_mask = y_hat != -1\n",
    "    return X_train[outlier_mask], y_train[outlier_mask]\n",
    "\n",
    "\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    X_train, y_train = process_outliers(X_train, y_train)\n",
    "    X_train, y_train = process_missing_values(X_train, y_train)\n",
    "    X_train, X_test = scale_data(X_train, X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,y):\n",
    "    kfold = KFold(n_splits=10, random_state=RSEED, shuffle=True)\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y.iloc[train_index,:], y.iloc[test_index,:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_metro_data(data):\n",
    "    data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "    data['year'] = pd.DatetimeIndex(data['date_time']).year\n",
    "    data['month'] = pd.DatetimeIndex(data['date_time']).month\n",
    "    data['week'] = data['date_time'].dt.week\n",
    "    data['day'] = pd.DatetimeIndex(data['date_time']).day\n",
    "    data['hour'] = data['date_time'].dt.hour\n",
    "    data['weather_main'] = data['weather_main'].astype('category')\n",
    "    data['weather_description'] = data['weather_description'].astype('category')\n",
    "    data = data.drop(['date_time'], axis=1)\n",
    "    dummy_columns = ['holiday', 'weather_main', 'weather_description']\n",
    "    dummies = pd.get_dummies(pd.DataFrame(data[dummy_columns]))\n",
    "    data = data.join(dummies)\n",
    "    data = data.drop(['weather_main'], axis=1)\n",
    "    data = data.drop(['weather_description'], axis=1)\n",
    "    data = data.drop(['holiday'], axis=1)\n",
    "    X = data.drop(['traffic_volume'], axis=1)\n",
    "    y = pd.DataFrame(data['traffic_volume'])\n",
    "    return data, X, y\n",
    "\n",
    "def prepare_news_data(data):\n",
    "    data = data_news.iloc[:,2:]\n",
    "    X = data.iloc[:,0:58]\n",
    "    y = data.iloc[:,58:59]\n",
    "    return data, X, y\n",
    "\n",
    "def prepare_real_estate_data(data):\n",
    "    data = data.iloc[:,1:]\n",
    "    x_columns = data.iloc[:,0:6].columns.str[3:]\n",
    "    y_column = data.iloc[:,6:7].columns.str[2:]\n",
    "    columns = x_columns.append(y_column)\n",
    "    data.columns = columns\n",
    "    X = data.iloc[:,0:6]\n",
    "    y = data.iloc[:,6:7]\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, file_type):\n",
    "    if (file_type == 'csv'):\n",
    "        return pd.read_csv(filename, sep=\",\")\n",
    "    return pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_metro_data(model, model_name):\n",
    "    dataset_name = \"data/dataset_MetroInterstateTrafficVolume.csv\"\n",
    "    data = get_data(dataset_name, 'csv')\n",
    "    data_prepared, X, y = prepare_metro_data(data)\n",
    "    X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "    predictions = train_and_predict(model, X_train, X_test, y_train)\n",
    "    evaluate_prediction(y_test, predictions, 'Metro Traffic Data', model_name)\n",
    "    \n",
    "def evaluate_model_on_news_data(model, model_name):\n",
    "    dataset_name = \"data/dataset_OnlineNewsPopularity.csv\"\n",
    "    data = get_data(dataset_name, 'csv')\n",
    "    data_prepared, X, y = prepare_news_data(data)\n",
    "    X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "    predictions = train_and_predict(model, X_train, X_test, y_train)\n",
    "    evaluate_prediction(y_test, predictions, 'Online News Data', model_name)\n",
    "\n",
    "def evaluate_model_on_real_estate_data(model, model_name):\n",
    "    dataset_name = \"data/dataset_RealEstateValuation.xlsx\"\n",
    "    data = get_data(dataset_name, 'xlsx')\n",
    "    data_prepared, X, y = prepare_real_estate_data(data)\n",
    "    X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "    predictions = train_and_predict(model, X_train, X_test, y_train)\n",
    "    evaluate_prediction(y_test, predictions, 'Real Estate Data', model_name)\n",
    "\n",
    "def evaluate_model(model, model_name):\n",
    "    evaluate_model_on_metro_data(model, model_name)\n",
    "    evaluate_model_on_news_data(model, model_name)\n",
    "    evaluate_model_on_real_estate_data(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso ,  Metro Traffic Data\n",
      "MSE:  3425543.4567353027 \n",
      "R2 Score:  0.13794854248935695\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lukas/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1047250123.5068359, tolerance: 465680728.0797145\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso ,  Online News Data\n",
      "MSE:  55343111.87012531 \n",
      "R2 Score:  -0.007111987771488915\n",
      "--------------------------------------------------\n",
      "Lasso ,  Real Estate Data\n",
      "MSE:  116.47192611377926 \n",
      "R2 Score:  0.45201503285664735\n",
      "--------------------------------------------------\n",
      "Ridge ,  Metro Traffic Data\n",
      "MSE:  3418693.946038037 \n",
      "R2 Score:  0.13967224874338302\n",
      "--------------------------------------------------\n",
      "Ridge ,  Online News Data\n",
      "MSE:  55318562.30385242 \n",
      "R2 Score:  -0.006665244506563139\n",
      "--------------------------------------------------\n",
      "Ridge ,  Real Estate Data\n",
      "MSE:  122.68646047793098 \n",
      "R2 Score:  0.42277647277630515\n",
      "--------------------------------------------------\n",
      "SVR ,  Metro Traffic Data\n",
      "MSE:  3289440.322996806 \n",
      "R2 Score:  0.172199430353689\n",
      "--------------------------------------------------\n",
      "SVR ,  Online News Data\n",
      "MSE:  57343813.60153968 \n",
      "R2 Score:  -0.04351996393284141\n",
      "--------------------------------------------------\n",
      "SVR ,  Real Estate Data\n",
      "MSE:  108.62199884867087 \n",
      "R2 Score:  0.48894789966822505\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model_svr = SVR()\n",
    "model_ridge = Ridge()\n",
    "model_lasso = Lasso()\n",
    "\n",
    "evaluate_model(model_lasso, 'Lasso')\n",
    "evaluate_model(model_ridge, 'Ridge')\n",
    "evaluate_model(model_svr, 'SVR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
