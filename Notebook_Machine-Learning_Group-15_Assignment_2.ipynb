{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import OneClassSVM, SVR\n",
    "from sklearn.linear_model import Ridge, SGDRegressor, Lasso\n",
    "\n",
    "from own_gradient_descent_regressor import OwnGradientDescentRegressor\n",
    "from own_knn_regressor import OwnKNeighborsRegressor\n",
    "\n",
    "# set random seed \n",
    "RSEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test read in data\n",
    "data_metro = pd.read_csv(\"data/dataset_MetroInterstateTrafficVolume.csv\", sep=\",\")\n",
    "data_news = pd.read_csv(\"data/dataset_OnlineNewsPopularity.csv\", sep=\",\")\n",
    "data_realestate = pd.read_excel(\"data/dataset_RealEstateValuation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(model, X_train, X_test, y_train, own_knn):\n",
    "    if(own_knn):\n",
    "        return model.findknearestNeighbors(X_train, y_train, X_test)\n",
    "    \n",
    "    model.fit(X_train,y_train.values.ravel())\n",
    "    return model.predict(X_test)\n",
    "\n",
    "def evaluate_prediction(y_test, y_pred, data_name, model_name):\n",
    "    mse = mean_squared_error(y_test, y_pred, squared=True)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(model_name, ', ', data_name)\n",
    "    print(\"MSE: \",mse,\"\\nRMSE: \",rmse,\"\\nR2 Score: \",r2)\n",
    "    print(\"-\"*50)\n",
    "    # g=plt.scatter(y_test, y_pred)\n",
    "    # g.axes.set_xlabel('True Values ')\n",
    "    # g.axes.set_ylabel('Predictions ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, y_train, y_test):\n",
    "    # reset index\n",
    "    X_train = X_train.reset_index().drop(['index'], axis=1)\n",
    "    X_test = X_test.reset_index().drop(['index'], axis=1)\n",
    "    y_train = y_train.reset_index().drop(['index'], axis=1)\n",
    "    y_test = y_test.reset_index().drop(['index'], axis=1)\n",
    "    \n",
    "    scaled_features_train = X_train.copy()\n",
    "    scaled_features_test = X_test.copy()\n",
    "\n",
    "    # only select numeric columns\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    columns_to_scale = X_train.select_dtypes(include=numerics).columns\n",
    "    \n",
    "    features_to_scale_train = scaled_features_train[columns_to_scale]\n",
    "    features_to_scale_test = scaled_features_test[columns_to_scale]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(features_to_scale_train)\n",
    "    scaled_features = pd.DataFrame(scaler.transform(features_to_scale_train))\n",
    "    scaled_features_train[columns_to_scale] = scaled_features\n",
    "    scaled_features = pd.DataFrame(scaler.transform(features_to_scale_test))\n",
    "    scaled_features_test[columns_to_scale] = scaled_features\n",
    "    \n",
    "    return scaled_features_train, scaled_features_test, y_train, y_test\n",
    "\n",
    "def process_missing_values(X_train, y_train):\n",
    "    # drop missing values\n",
    "    X_train = X_train.dropna()\n",
    "    y_train = y_train.dropna()\n",
    "    \n",
    "    return X_train, y_train\n",
    "\n",
    "def process_outliers(X_train, y_train):\n",
    "    # only select numeric columns\n",
    "    numerics = ['uint8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    X_train = X_train.select_dtypes(include=numerics)\n",
    "\n",
    "    # identify outliers in the training dataset\n",
    "    outlier_predictor = OneClassSVM(nu=0.02)\n",
    "    y_hat = outlier_predictor.fit_predict(X_train)\n",
    "    unique, counts = np.unique(y_hat, return_counts=True)\n",
    "\n",
    "    # select all rows that are not outliers\n",
    "    outlier_mask = y_hat != -1\n",
    "    return X_train[outlier_mask], y_train[outlier_mask]\n",
    "\n",
    "\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    X_train, y_train = process_outliers(X_train, y_train)\n",
    "    X_train, y_train = process_missing_values(X_train, y_train)\n",
    "    X_train, X_test, y_train, y_test = scale_data(X_train, X_test, y_train, y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,y):\n",
    "    kfold = KFold(n_splits=10, random_state=RSEED, shuffle=True)\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y.iloc[train_index,:], y.iloc[test_index,:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_metro_data(data):\n",
    "    data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "    data['year'] = pd.DatetimeIndex(data['date_time']).year\n",
    "    data['month'] = pd.DatetimeIndex(data['date_time']).month\n",
    "    data['week'] = data['date_time'].dt.week\n",
    "    data['day'] = pd.DatetimeIndex(data['date_time']).day\n",
    "    data['hour'] = data['date_time'].dt.hour\n",
    "    data['weather_main'] = data['weather_main'].astype('category')\n",
    "    data['weather_description'] = data['weather_description'].astype('category')\n",
    "    data = data.drop(['date_time'], axis=1)\n",
    "    dummy_columns = ['holiday', 'weather_main', 'weather_description']\n",
    "    dummies = pd.get_dummies(pd.DataFrame(data[dummy_columns]))\n",
    "    data = data.join(dummies)\n",
    "    data = data.drop(['weather_main'], axis=1)\n",
    "    data = data.drop(['weather_description'], axis=1)\n",
    "    data = data.drop(['holiday'], axis=1)\n",
    "    X = data.drop(['traffic_volume'], axis=1)\n",
    "    y = pd.DataFrame(data['traffic_volume'])\n",
    "    return data, X, y\n",
    "\n",
    "def prepare_news_data(data):\n",
    "    data = data_news.iloc[:,2:]\n",
    "    X = data.iloc[:,0:58]\n",
    "    y = data.iloc[:,58:59]\n",
    "    return data, X, y\n",
    "\n",
    "def prepare_real_estate_data(data):\n",
    "    data = data.iloc[:,1:]\n",
    "    x_columns = data.iloc[:,0:6].columns.str[3:]\n",
    "    y_column = data.iloc[:,6:7].columns.str[2:]\n",
    "    columns = x_columns.append(y_column)\n",
    "    data.columns = columns\n",
    "    X = data.iloc[:,0:6]\n",
    "    y = data.iloc[:,6:7]\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, file_type):\n",
    "    if (file_type == 'csv'):\n",
    "        return pd.read_csv(filename, sep=\",\")\n",
    "    return pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_metro_data(model, model_name, own_knn):\n",
    "    dataset_name = \"data/dataset_MetroInterstateTrafficVolume.csv\"\n",
    "    data = get_data(dataset_name, 'csv')\n",
    "    data_prepared, X, y = prepare_metro_data(data)\n",
    "    X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "    predictions = train_and_predict(model, X_train, X_test, y_train, own_knn)\n",
    "    evaluate_prediction(y_test, predictions, 'Metro Traffic Data', model_name)\n",
    "    \n",
    "def evaluate_model_on_news_data(model, model_name, own_knn):\n",
    "    dataset_name = \"data/dataset_OnlineNewsPopularity.csv\"\n",
    "    data = get_data(dataset_name, 'csv')\n",
    "    data_prepared, X, y = prepare_news_data(data)\n",
    "    X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "    predictions = train_and_predict(model, X_train, X_test, y_train, own_knn)\n",
    "    evaluate_prediction(y_test, predictions, 'Online News Data', model_name)\n",
    "\n",
    "def evaluate_model_on_real_estate_data(model, model_name, own_knn):\n",
    "    dataset_name = \"data/dataset_RealEstateValuation.xlsx\"\n",
    "    data = get_data(dataset_name, 'xlsx')\n",
    "    data_prepared, X, y = prepare_real_estate_data(data)\n",
    "    X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "    predictions = train_and_predict(model, X_train, X_test, y_train, own_knn)\n",
    "    evaluate_prediction(y_test, predictions, 'Real Estate Data', model_name)\n",
    "\n",
    "def evaluate_model(model, model_name, own_knn=False):\n",
    "    # evaluate_model_on_metro_data(model, model_name, own_knn)\n",
    "    # evaluate_model_on_news_data(model, model_name, own_knn)\n",
    "    evaluate_model_on_real_estate_data(model, model_name, own_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_svr = SVR()\n",
    "model_ridge = Ridge()\n",
    "model_lasso = Lasso()\n",
    "gdr_own = OwnGradientDescentRegressor()\n",
    "model_own_knn_1 = OwnKNeighborsRegressor(n_neighbors=1)\n",
    "model_own_knn_5 = OwnKNeighborsRegressor(n_neighbors=5)\n",
    "model_own_knn_10 = OwnKNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "# evaluate_model(model_lasso, 'Lasso')\n",
    "# evaluate_model(model_ridge, 'Ridge')\n",
    "# evaluate_model(model_svr, 'SVR')\n",
    "# evaluate_model(model_own_knn_1, 'Own_KNN N=1', True)\n",
    "# evaluate_model(model_own_knn_5, 'Own_KNN N=5', True)\n",
    "# evaluate_model(model_own_knn_10, 'Own_KNN N=10', True)\n",
    "# evaluate_model(gdr_own, 'SGDR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
